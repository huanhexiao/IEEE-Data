{"citations": [], "references": [], "details": {"publisher": "TUP", "issue_date": "Feb. 2007", "doi": "10.1016/S1007-0214(07)70008-1", "title": "Personalized multi-view face animation with lifelike textures", "abstract": "Realistic personalized face animation mainly depends on a picture-perfect appearance and natural head rotation. This paper describes a face model for generation of novel view facial textures with various realistic expressions and poses. The model is achieved from corpora of a talking person using machine learning techniques. In face modeling, the facial texture variation is expressed by a multi-view facial texture space model, with the facial shape variation represented by a compact 3-D point distribution model (PDM). The facial texture space and the shape space are connected by bridging 2-D mesh structures. Levenberg-Marquardt optimization is employed for fine model fitting. Animation trajectory is trained for smooth and continuous image sequences. The test results show that this approach can achieve a vivid talking face sequence in various views. Moreover, the animation complexity is significantly reduced by the vector representation.", "journal_title": "Tsinghua Science and Technology", "firstpage": "51", "volume": "12", "lastpage": "57", "date_publication": "Feb. 2007", "sponsor": "Tsinghua University Press (TUP)", "date": "Feb. 2007", "date_current_version": "Tue Jan 17 00:00:00 EST 2012", "issue": "1", "pages": "51 - 57"}, "authors": ["Yanghua Liu", "Guangyou Xu"], "keywords": ["Animation", "Computational modeling", "Face", "Prototypes", "Shape", "Solid modeling", "Vectors", "face animation", "multi-view", "point distribution model (PDM)", "texture", ""], "arnumber": "6076178"}