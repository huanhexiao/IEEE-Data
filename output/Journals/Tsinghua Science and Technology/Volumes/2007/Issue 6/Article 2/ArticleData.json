{"citations": [], "references": [], "details": {"publisher": "TUP", "issue_date": "Dec. 2007", "doi": "10.1016/S1007-0214(07)70168-2", "title": "Semi-supervised additive logistic regression: A gradient descent solution", "abstract": "This paper describes a semi-supervised regularized method for additive logistic regression. The graph regularization term of the combined functions is added to the original cost functional used in AdaBoost. This term constrains the learned function to be smooth on a graph. Then the gradient solution is computed with the advantage that the regularization parameter can be adaptively selected. Finally, the function step-size of each iteration can be computed using Newton-Raphson iteration. Experiments on benchmark data sets show that the algorithm gives better results than existing methods.", "journal_title": "Tsinghua Science and Technology", "firstpage": "638", "volume": "12", "lastpage": "646", "date_publication": "Dec. 2007", "sponsor": "Tsinghua University Press (TUP)", "date": "Dec. 2007", "date_current_version": "Tue Jan 17 00:00:00 EST 2012", "issue": "6", "pages": "638 - 646"}, "authors": ["Yangqiu Song", "Qutang Cai", "Feiping Nie", "Changshui Zhang"], "keywords": ["Additives", "Boosting", "Fitting", "Laplace equations", "Logistics", "Manifolds", "Signal processing algorithms", "Boosting", "graph regularization", "semi-supervised", ""], "arnumber": "6071811"}