{"citations": [], "references": [], "details": {"publisher": "TUP", "issue_date": "Dec. 2013", "doi": "10.1109/TST.2013.6678904", "title": "CUDA's mapped memory to support I/O functions on GPU", "abstract": "The API interfaces provided by CUDA help programmers to get high performance CUDA applications in GPU, but they cannot support most I/O operations in device codes. The characteristics of CUDA's mapped memory are used here to create a dynamic polling service model in the host which can satisfy most I/O functions such as read/write file and \u201cprintf\u201d. The technique to implement these I/O functions has some influence on the performance of the original applications. These functions quickly respond to the users' I/O requirements with the \u201cprintf\u201d performance better than CUDA's. An easy and effective real-time method is given for users to debug their programs using the I/O functions. These functions improve productivity of converting legacy C/C++ codes to CUDA and broaden CUDA's functions.", "journal_title": "Tsinghua Science and Technology", "firstpage": "588", "volume": "18", "lastpage": "598", "date_publication": "Dec. 2013", "inspec": "15568220", "date": "Dec. 2013", "date_current_version": "Fri Dec 06 00:00:00 EST 2013", "issue": "6", "pages": "588 - 598", "sponsor": "Tsinghua University Press (TUP)"}, "authors": ["Wei Wu", "Fengbin Qi", "Wangquan He", "Shanshan Wang"], "keywords": ["application program interfaces", "graphics processing units", "parallel architectures", "API interfaces", "C/C++ codes", "CUDA mapped memory", "GPU", "I/O functions", "dynamic polling service model", "printf performance", "Coherence", "Graphics processing units", "Instruction sets", "Kernel", "Libraries", "Message systems", "CUDA", "I/O functions", "dynamic polling service model", "mapped memory", ""], "arnumber": "6678904"}